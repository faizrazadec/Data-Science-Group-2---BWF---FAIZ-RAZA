{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f64f9a-2c77-434f-9ee0-d0112a6f4f44",
   "metadata": {},
   "source": [
    "# Evaluation Techniques for Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a41e1-003a-4573-ac25-1dcfe2bc35e6",
   "metadata": {},
   "source": [
    "### Importance of Evaluation in Regression\n",
    "\n",
    "Evaluation is a crucial step in the regression analysis process. It provides insight into how well a regression model performs and helps to understand its effectiveness in making predictions. Here are several key reasons why evaluation is important in regression:\n",
    "\n",
    "#### 1. **Assess Model Performance**\n",
    "   - **Accuracy**: Evaluation metrics help quantify how accurately the model predicts the dependent variable.\n",
    "   - **Quality Check**: By evaluating the model, you can check if it is performing well or if there are significant errors that need addressing.\n",
    "\n",
    "#### 2. **Understand Model Fit**\n",
    "   - **Goodness-of-Fit**: Metrics such as R² (Coefficient of Determination) and Explained Variance Score help understand how well the model explains the variability of the target variable.\n",
    "   - **Residual Analysis**: Evaluation helps analyze residuals (differences between observed and predicted values) to assess if the model assumptions are met.\n",
    "\n",
    "#### 3. **Compare Models**\n",
    "   - **Selection of Best Model**: Evaluation metrics allow for the comparison of different regression models to choose the best one based on performance criteria.\n",
    "   - **Benchmarking**: Helps in benchmarking the model's performance against baseline or existing models.\n",
    "\n",
    "#### 4. **Identify Overfitting or Underfitting**\n",
    "   - **Overfitting**: Evaluation metrics can indicate if a model is too complex and fits the training data too closely, potentially harming generalization to new data.\n",
    "   - **Underfitting**: Metrics help in identifying if a model is too simple and fails to capture the underlying patterns in the data.\n",
    "\n",
    "#### 5. **Guide Model Improvement**\n",
    "   - **Error Analysis**: By evaluating the model, you can identify areas where predictions are inaccurate and use this information to refine or improve the model.\n",
    "   - **Feature Engineering**: Evaluation can provide insights into which features are important and which may need to be adjusted or added.\n",
    "\n",
    "#### 6. **Communicate Results**\n",
    "   - **Stakeholder Understanding**: Evaluation metrics provide a clear, quantitative way to communicate the performance of the model to stakeholders, decision-makers, or clients.\n",
    "   - **Documentation**: Evaluation results are essential for documenting the model development process and ensuring transparency in model performance.\n",
    "\n",
    "#### 7. **Ensure Robustness**\n",
    "   - **Cross-Validation**: Evaluation often involves techniques like cross-validation to ensure that the model generalizes well across different subsets of the data.\n",
    "   - **Performance Stability**: Helps in checking if the model's performance is stable across various data distributions or conditions.\n",
    "\n",
    "#### 8. **Optimize Model Parameters**\n",
    "   - **Hyperparameter Tuning**: Evaluation metrics are used in conjunction with techniques like grid search or random search to tune model parameters for optimal performance.\n",
    "   - **Model Selection**: Helps in choosing the right model complexity and configuration.\n",
    "\n",
    "#### Common Evaluation Metrics in Regression:\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**: Measures the average magnitude of errors in predictions, without considering their direction.\n",
    "\n",
    "2. **Mean Squared Error (MSE)**: Measures the average of the squares of the errors, giving more weight to larger errors.\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**: Provides the square root of MSE, giving errors in the same unit as the target variable.\n",
    "\n",
    "4. **R² (Coefficient of Determination)**: Indicates the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "5. **Mean Absolute Percentage Error (MAPE)**: Measures the accuracy as a percentage of the error, providing a relative measure of performance.\n",
    "\n",
    "6. **Explained Variance Score**: Indicates the proportion of variance in the target variable that is explained by the model.\n",
    "\n",
    "7. **Max Error**: Measures the maximum absolute error between actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac9095-d4dd-4070-a094-5a8cb8f242d2",
   "metadata": {},
   "source": [
    "### Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3967ef03-cec5-4599-aab7-09aff32e669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, root_mean_squared_log_error, r2_score, max_error, mean_pinball_loss, mean_poisson_deviance, mean_gamma_deviance, mean_tweedie_deviance, mean_absolute_percentage_error, median_absolute_error, d2_tweedie_score, d2_absolute_error_score, d2_pinball_score, explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ecca9-5bb9-49f7-88fc-1cce1aca53b2",
   "metadata": {},
   "source": [
    "### Reading the Dataset File\n",
    "- `This dataset is created my me, while integrating the the flappy bird game with the dnn model, to automate the bird to move by itself`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006178a3-f936-460c-986e-c27e65a9a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird_y</th>\n",
       "      <th>pipe_x</th>\n",
       "      <th>BIRD_VELOCITY</th>\n",
       "      <th>pipe_gap_y</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bird_y  pipe_x  BIRD_VELOCITY  pipe_gap_y  reward\n",
       "0     300     597            0.0         145     0.1\n",
       "1     300     594            0.0         145     0.1\n",
       "2     300     591            0.0         145     0.1\n",
       "3     300     588            0.0         145     0.1\n",
       "4     300     585            0.0         145     0.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Flappy_bird_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe39a54-14b8-4e8f-a020-d8675293e784",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "- Define the function, it'll train the model and do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bcfbbcf-3e26-486d-9897-b87d70b3beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "[363.30171831 278.2740386  545.23516131 233.55703457 206.81331711\n",
      " 229.74424839 333.48990286 106.07548021 254.77658926 222.39681198]\n"
     ]
    }
   ],
   "source": [
    "def linear_regression(df):\n",
    "    global y_pred, y_test, x_test\n",
    "    x = df.drop(['bird_y'], axis = 1)\n",
    "    y = df['bird_y']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    df_model = model.fit(x_train, y_train)\n",
    "    print(df_model)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(y_pred[:10])\n",
    "\n",
    "linear_regression(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0cd6f-c4c2-4f50-b4d8-d53d0a22287f",
   "metadata": {},
   "source": [
    "### Mean Absolute Error(MAE)\n",
    "- MAE is a very simple metric which calculates the absolute difference between actual and predicted values.\n",
    "\n",
    "- To better understand, let’s take an example you have input data and output data and use Linear Regression, which draws a best-fit line.\n",
    "\n",
    "- Now you have to find the MAE of your model which is basically a mistake made by the model known as an error. Now find the difference between the actual value and predicted value that is an absolute error but we have to find the mean absolute of the complete dataset.\n",
    "\n",
    "- so, sum all the errors and divide them by a total number of observations And this is MAE. And we aim to get a minimum MAE because this is a loss.\n",
    "![online](https://editor.analyticsvidhya.com/uploads/71890MAE%20Formula.png)\n",
    "- **Advantages of MAE**\n",
    "The MAE you get is in the same unit as the output variable.\n",
    "It is most Robust to outliers.\n",
    "- **Disadvantages of MAE**\n",
    "The graph of MAE is not differentiable so we have to apply various optimizers like Gradient descent which can be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b05502-142a-4b91-ab36-e65a558d504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.08896195883062"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_absolute_error(y_test, y_pred)\n",
    "eva  #118 is the larger term which shows that our model is not fitted well, it have the larger error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb4672-0f06-4017-b02b-6d980a217be5",
   "metadata": {},
   "source": [
    "**Now to overcome the disadvantage of MAE next metric came as MSE.**\n",
    "\n",
    "### Mean Squared Error(MSE)\n",
    "- MSE is a most used and very simple metric with a little bit of change in mean absolute error. Mean squared error states that finding the squared difference between actual and predicted value.\n",
    "\n",
    "- So, above we are finding the absolute difference and here we are finding the squared difference.\n",
    "\n",
    "- **What actually the MSE represents?** It represents the squared distance between actual and predicted values. we perform squared to avoid the cancellation of negative terms and it is the benefit of MSE.\n",
    "\n",
    "![online](https://lh3.googleusercontent.com/-JBio3Q_1FiI/YB2oQKEmRBI/AAAAAAAAAkM/c8KJ3wPwtMEd3Ik0nYMMdmr_pRqMF6MlQCLcBGAsYHQ/w550-h177/image.png)\n",
    "\n",
    "**Advantages of MSE**\n",
    "\n",
    "The graph of MSE is differentiable, so you can easily use it as a loss function.\n",
    "\n",
    "**Disadvantages of MSE**\n",
    "\n",
    "The value you get after calculating MSE is a squared unit of output. for example, the output variable is in meter(m) then after calculating MSE the output we get is in meter squared.\n",
    "If you have outliers in the dataset then it penalizes the outliers most and the calculated MSE is bigger. So, in short, It is not Robust to outliers which were an advantage in MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60a07e46-9e5a-4b78-b604-be6fe92f5a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46604.29846025482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_squared_error(y_test, y_pred)\n",
    "eva #the mse value is oso much, because the output is in different unit which is the squared of the input unit, this shows that we have a greater error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856afc1-d1bb-4bc0-ae60-626d0a816b55",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error(RMSE)\n",
    "- As RMSE is clear by the name itself, that it is a simple square root of mean squared error.\n",
    "\n",
    "![online](https://editor.analyticsvidhya.com/uploads/34962RMSLE%20Formula.png)\n",
    "\n",
    "**Advantages of RMSE**\n",
    "- The output value you get is in the same unit as the required output variable which makes interpretation of loss easy.\n",
    "**Disadvantages of RMSE**\n",
    "- It is not that robust to outliers as compared to MAE.\n",
    "for performing RMSE we have to NumPy NumPy square root function over MSE.\n",
    "\n",
    "- Most of the time people use RMSE as an evaluation metric and mostly when you are working with deep learning techniques the most preferred metric is RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9370abde-91b8-400d-b6b9-f0501fd591f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215.88028733595576"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = root_mean_squared_error(y_test, y_pred)\n",
    "eva #this is in the same unit as input but still the large value shows that we have a larger error in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e72b1-a419-44ac-aef9-588b29007f9d",
   "metadata": {},
   "source": [
    "### Root Mean Squared Log Error(RMSLE)\n",
    "- Taking the log of the RMSE metric slows down the scale of error. The metric is very helpful when you are developing a model without calling the inputs. In that case, the output will vary on a large scale.\n",
    "\n",
    "- To control this situation of RMSE we take the log of calculated RMSE error and resultant we get as RMSLE.\n",
    "\n",
    "- To perform RMSLE we have to use the NumPy log function over RMSE.\n",
    "\n",
    "- It is a very simple metric that is used by most of the datasets hosted for Machine Learning competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d10fbba2-62ad-409f-b00d-8957aefb2121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5406595542262108"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = root_mean_squared_log_error(y_test, y_pred)\n",
    "eva #it's showing us the error in the log scale that's all the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960a945-376d-4131-a7ff-dc3d5c36a0be",
   "metadata": {},
   "source": [
    "### R Squared (R2)\n",
    "- R2 score is a metric that tells the performance of your model, not the loss in an absolute sense that how many wells did your model perform.\n",
    "\n",
    "- In contrast, MAE and MSE depend on the context as we have seen whereas the R2 score is independent of context.\n",
    "\n",
    "- So, with help of R squared we have a baseline model to compare a model which none of the other metrics provides. The same we have in classification problems which we call a threshold which is fixed at 0.5. So basically R2 squared calculates how must regression line is better than a mean line.\n",
    "\n",
    "- Hence, R2 squared is also known as *Coefficient of Determination* or sometimes also known as *Goodness of fit.*\n",
    "\n",
    "![online](https://editor.analyticsvidhya.com/uploads/22091R2%20Squared%20Formula.png)\n",
    "\n",
    "**R2 Squared**\n",
    "- Now, how will you interpret the R2 score? suppose If the R2 score is zero then the above regression line by mean line is equal means 1 so 1-1 is zero. So, in this case, both lines are overlapping means model performance is worst, It is not capable to take advantage of the output column.\n",
    "\n",
    "- Now the second case is when the R2 score is 1, it means when the division term is zero and it will happen when the regression line does not make any mistake, it is perfect. In the real world, it is not possible.\n",
    "\n",
    "- So we can conclude that as our regression line moves towards perfection, R2 score move towards one. And the model performance improves.\n",
    "\n",
    "- The normal case is when the R2 score is between zero and one like 0.8 which means your model is capable to explain 80 per cent of the variance of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0a0afd3-7509-47cb-8b51-75c195ff60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151614981513495"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = r2_score(y_test, y_pred)\n",
    "eva  #r2 score is not the loss of t he function, it's basically the score of the model which tell us how our model is performing, as the score moves to\n",
    "#it means the model is performing better and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4006f0-e72c-40db-800f-c5e2cca62a94",
   "metadata": {},
   "source": [
    "### Adjusted R Squared\n",
    "- The disadvantage of the R2 score is while adding new features in data the R2 score starts increasing or remains constant but it never decreases because It assumes that while adding more data variance of data increases.\n",
    "\n",
    "- But the problem is when we add an irrelevant feature in the dataset then at that time R2 sometimes starts increasing which is incorrect.\n",
    "\n",
    "- Hence, To control this situation Adjusted R Squared came into existence.\n",
    "\n",
    "\n",
    "![online](https://lh3.googleusercontent.com/-6T1LxrK1by8/YB6D5hjSCjI/AAAAAAAAAlk/gCmLpEJMJ3MpwO6r-sI7GQzuOQP2I1B3QCLcBGAsYHQ/w332-h179/image.png)\n",
    "\n",
    "\n",
    "**r2a**\n",
    "- Now as K increases by adding some features so the denominator will decrease, n-1 will remain constant. R2 score will remain constant or will increase slightly so the complete answer will increase and when we subtract this from one then the resultant score will decrease. so this is the case when we add an irrelevant feature in the dataset.\n",
    "\n",
    "- And if we add a relevant feature then the R2 score will increase and 1-R2 will decrease heavily and the denominator will also decrease so the complete term decreases, and on subtracting from one the score increases.\n",
    "\n",
    "\n",
    "Hence, this metric becomes one of the most important metrics to use during the evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86a0e1cd-e7e3-4e29-a997-03af30d5c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4889540115649359\n"
     ]
    }
   ],
   "source": [
    "n=40\n",
    "k=2\n",
    "adj_r2_score = 1 - ((1-eva)*(n-1)/(n-k-1))\n",
    "print(adj_r2_score)\n",
    "\n",
    "#the problem with the r2 square was that when we add new features the r2 says the model is performing more better than before, it thinks that the model\n",
    "#performance will increase with the variance, but if the irrelevant feature will added, it'll decrese the performance or the performance will stay\n",
    "#constant so overcome the adjusted r2 comes, which adds the parameter for irrelevant for upcomming features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5665a6c-99a7-4207-8ead-3285fbc30caa",
   "metadata": {},
   "source": [
    "### median_absolute_error\n",
    "- **Description**: The median of the absolute differences between predicted and actual values. It is a robust measure of error.\n",
    "- **Advantages**: Robust to outliers, providing a measure of central tendency for error.\n",
    "- **Disadvantages**: Less commonly used compared to mean absolute error\n",
    "\n",
    "![local](images/mar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc0c8adb-91a4-4c98-98a4-4a1a5796f0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.42096104604173"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = median_absolute_error(y_test, y_pred)\n",
    "eva \n",
    "#The Median Absolute Error (MedAE) is a robust measure of central tendency for errors in a regression model.\n",
    "#It calculates the median of the absolute differences between predicted and actual values. Unlike the mean absolute error (MAE),\n",
    "#which averages the absolute errors, MedAE takes the median of these errors. This makes MedAE less sensitive to outliers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afeddd4-07ac-4a9d-90b2-b19179402514",
   "metadata": {},
   "source": [
    "### mean_absolute_percentage_error\n",
    "- **Description**: The mean absolute percentage error (MAPE) measures the accuracy of a forecast as a percentage. It is the average of the absolute percentage errors.\n",
    "- **Advantages**: Easy to interpret, expressed as a percentage.\n",
    "- **Disadvantages**: Can be undefined if actual values are zero and can be skewed if actual values are very small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f42f429-965f-489b-a187-7e4383455ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4466306299353287"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_absolute_percentage_error(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1de29-e031-4137-a4ef-47e5217e9e32",
   "metadata": {},
   "source": [
    "### mean_tweedie_deviance\n",
    "- **Description**: Measures the goodness of fit for a model predicting data that follows a Tweedie distribution, which includes Poisson, Gamma, and compound Poisson-Gamma distributions.\n",
    "- **Advantages**: Flexible, applicable to a variety of distributions.\n",
    "- **Disadvantages**: Requires specifying the power parameter, which might not be straightforward.\n",
    "\n",
    "![local](images/mtd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d1ae4ab-a84c-40b1-9d7b-52126948bf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46604.29846025482"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_tweedie_deviance(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fc735-6f0a-48ba-bb4f-56310d011dd9",
   "metadata": {},
   "source": [
    "### mean_gamma_deviance\n",
    "- **Description**: Measures the goodness of fit for a model predicting positive continuous data based on the Gamma distribution.\n",
    "- **Advantages**: Suitable for data with positive continuous outcomes.\n",
    "- **Disadvantages**: Assumes the data follows a Gamma distribution, which might not always be the case.\n",
    "\n",
    "![local](images/mgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cdb3f40-46b1-431c-a962-40efee40dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35950065355252037"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_gamma_deviance(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b3162-5573-48fe-b22e-de52513febac",
   "metadata": {},
   "source": [
    "### mean_poisson_deviance\n",
    "- **Description**: Measures the goodness of fit for a model predicting count data based on the Poisson distribution.\n",
    "- **Advantages**: Suitable for count data and models predicting event rates.\n",
    "- **Disadvantages**: Assumes the data follows a Poisson distribution, which might not always be the case.\n",
    "\n",
    "![local](images/mpd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef778dc8-a909-4a6e-86de-cbba5620d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.16875722900177"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_poisson_deviance(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc847f-d6f8-4612-b46b-a272d5b6aa2f",
   "metadata": {},
   "source": [
    "### mean_pinball_loss\n",
    "- **Description**: The average pinball loss over all quantiles for quantile regression. It is used to measure the accuracy of quantile predictions.\n",
    "- **Advantages**: Useful for evaluating quantile regression models.\n",
    "- **Disadvantages**: Requires understanding of pinball loss and quantile regression.\n",
    "\n",
    "![local](images/mpl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52fc0501-607c-4d4c-806b-49497f2f4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830.7105898712578"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = max_error(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa819f-3264-48e0-8e21-074b09fcb2b1",
   "metadata": {},
   "source": [
    "### max_error\n",
    "- **Description**: The maximum absolute difference between predicted and actual values. It represents the worst-case error of the model.\n",
    "- **Advantages**: Provides insight into the worst prediction error.\n",
    "- **Disadvantages**: Sensitive to outliers and does not provide information about overall model performance.\n",
    "\n",
    "![local](images/me.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23b5514b-795e-48de-81b3-b805aa6fa8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4466306299353287"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = mean_absolute_percentage_error(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4488b-a22d-4caa-a6ae-585538b52031",
   "metadata": {},
   "source": [
    "### explained_variance_score\n",
    "- **Description**: Measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with 1 indicating perfect prediction.\n",
    "- **Advantages**: Directly interpretable as the proportion of explained variance.\n",
    "- **Disadvantages**: Can be misleading when used with data that has non-linear relationships.\n",
    "\n",
    "![local](images/evs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ede4ed65-8e5f-40f0-9ecf-1384be5ba578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5198317077117782"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = explained_variance_score(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcb5a5-2100-476d-a374-d1a0dce8c83a",
   "metadata": {},
   "source": [
    "### d2_pinball_score\n",
    "- **Description**: The D² based on pinball loss is a metric for quantile regression models, measuring the goodness of fit based on quantile loss.\n",
    "- **Advantages**: Suitable for models predicting quantiles instead of means.\n",
    "- **Disadvantages**: Less commonly used and requires understanding of quantile loss.\n",
    "\n",
    "![local](images/d2p.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c887ec5f-f17e-4160-a996-b38a14465fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.835748516029419e-05"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = d2_pinball_score(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bde493-27ee-4f05-a9f2-eebf9cec13e7",
   "metadata": {},
   "source": [
    "### d2_absolute_error_score\n",
    "- **Description**: The D² based on absolute error is similar to R² but uses absolute errors rather than squared errors. It measures the proportion of absolute error explained by the model.\n",
    "- **Advantages**: More robust to outliers than metrics based on squared errors.\n",
    "- **Disadvantages**: Less commonly used and may be less intuitive for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6139889a-0261-4c26-9064-5cc7ffbe4436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.835748516029419e-05"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = d2_absolute_error_score(y_test, y_pred)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bedd5-63c0-4c1e-bc54-e4dbd994642b",
   "metadata": {},
   "source": [
    "### d2_tweedie_score\n",
    "- **Description**: The D² (also known as pseudo-R²) of a Tweedie deviance regression model is a measure of how well the model explains the variability of the response variable. It ranges from -∞ to 1, with 1 indicating a perfect fit.\n",
    "- **Advantages**: Takes into account both the mean and variance structure of the data.\n",
    "- **Disadvantages**: Requires specifying the power parameter of the Tweedie distribution, which might not be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efff99e9-0498-44b9-bf43-9cad00ef1612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151614981513495"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva = d2_tweedie_score(y_test, y_pred)\n",
    "eva"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
